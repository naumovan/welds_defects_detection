import cv2
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
from ultralytics import YOLO
from sahi import AutoDetectionModel
from sahi.predict import get_prediction, get_sliced_prediction
from sahi.utils.cv import visualize_object_predictions

MODEL_PATH_NANO = "models/20240615_5_classes_640_8n_150_90_10_iter_train_aug/weights/best.pt"

st.set_page_config(
    page_title="–î–µ—Ç–µ–∫—Ü–∏—è —Å–≤–∞—Ä–Ω—ã—Ö —à–≤–æ–≤",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("–î–µ—Ç–µ–∫—Ü–∏—è —Å–≤–∞—Ä–Ω—ã—Ö —à–≤–æ–≤")

st.sidebar.text("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏")
st.sidebar.title("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏")

menu = ["Yolov8n", "Yolov8s", "Yolov8n+SAHI", "Yolov8s+SAHI"]
choice = st.sidebar.selectbox("", menu)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
confidence = float(st.sidebar.slider(
    "–ö–æ—Ñ–∏–¥–µ–Ω—Å", 25, 100, 40)) / 100

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ SAHI
if choice in ["Yolov8n+SAHI", "Yolov8s+SAHI"]:
    st.sidebar.title("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ SAHI")
    size_window_sahi = st.sidebar.slider("–†–∞–∑–º–µ—Ä —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞", 64, 512, 128, 64)
else:
    size_window_sahi = None

def load_and_display_image():
    image_file = st.file_uploader("Upload Images", type=["png", "jpg", "jpeg"])
    if image_file is not None:
        file_details = {"filename": image_file.name, "filetype": image_file.type,
                        "filesize": image_file.size}
        st.write(file_details)
        bytes_data = image_file.read()
        image_orig = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        image_orig = cv2.cvtColor(image_orig, cv2.COLOR_BGR2RGB)
        return image_orig
    return None

def detect_defects(image, model, model_classes, choice, confidence, size_window_sahi=None):
    class_counts = {}

    if choice != "Yolov8n+SAHI" and choice != "Yolov8s+SAHI":
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º YOLO –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        res = model(image, conf=confidence)
        boxes = res[0].boxes
        st.image(res[0].plot(), caption='–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏', use_column_width=True)

        for box in boxes:
            cls = box.cls
            class_name = model.names[int(cls)]
            if class_name in class_counts:
                class_counts[class_name] += 1
            else:
                class_counts[class_name] = 1
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SAHI –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        res = get_prediction(image, model)
        res.export_visuals(export_dir="demo_data/")

        results = get_sliced_prediction(
            image,
            model,
            slice_height=size_window_sahi,
            slice_width=size_window_sahi,
            overlap_height_ratio=0.2,
            overlap_width_ratio=0.2,
        )

        if results.object_prediction_list:
            boxes_xy, boxes_scores, boxes_classes = [], [], []
            for result in results.object_prediction_list:
                boxes_xy.append(result.bbox.to_xyxy())
                boxes_scores.append(result.score.value)
                boxes_classes.append(result.category.id)

                class_name = model_classes[result.category.id]
                if class_name in class_counts:
                    class_counts[class_name] += 1
                else:
                    class_counts[class_name] = 1

            boxes_xy = np.array(boxes_xy, dtype=int)
            boxes_scores = np.array(boxes_scores)
            boxes_classes = np.array(boxes_classes, dtype=int)

            image_visual = image.copy()

            for box, score, cls in zip(boxes_xy, boxes_scores, boxes_classes):
                if len(box) == 4:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                    x1, y1, x2, y2 = box
                    cv2.rectangle(image_visual, (x1, y1), (x2, y2), (0, 0, 255), 3)
                    cv2.putText(image_visual, f'{model_classes[cls]} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)

            st.image(image_visual, caption='–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ SAHI', use_column_width=True)

    return class_counts

def main():
    image = load_and_display_image()
    if image is not None:
        col1, col2 = st.columns(2)

        with col1:
            st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)

        with col2:
            if st.sidebar.button('–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–µ—Ñ–µ–∫—Ç—ã'):
                if choice in ["Yolov8n", "Yolov8s"]:
                    model = YOLO(MODEL_PATH_NANO)
                    model_classes = model.names
                elif choice in ["Yolov8n+SAHI", "Yolov8s+SAHI"]:
                    model = AutoDetectionModel.from_pretrained(
                        model_type="yolov8",
                        model_path=MODEL_PATH_NANO,
                        confidence_threshold=confidence,
                        device="cpu",  # or 'cuda:0'
                    )
                    model_classes = YOLO(MODEL_PATH_NANO).model.names

                class_counts = detect_defects(image, model, model_classes, choice, confidence, size_window_sahi)

                if class_counts:
                    st.sidebar.title("–î–∏–∞–≥—Ä–∞–º–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤")
                    fig, ax = plt.subplots()
                    ax.bar(class_counts.keys(), class_counts.values())
                    ax.set_xlabel('–ö–ª–∞—Å—Å—ã')
                    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
                    st.sidebar.pyplot(fig)

if __name__ == "__main__":
    main()
